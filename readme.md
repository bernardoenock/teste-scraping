## Run

Coloque sua API_KEY no .env:
- `API_KEY="3x3mpl0d3um44p1k31"`


Rodar o banco mongoDB com docker:
- `docker run --name mongodb -d -p 27017:27017 mongo`

Ou com sua conta official seguindo a [documenta√ß√£o do mongoDB](https://www.mongodb.com/docs/atlas/tutorial/connect-to-your-cluster/):
- `from pymongo import MongoClient`
- `client = MongoClient('<connection-string>')` ou `client = AsyncIOMotorClient('<connection-string>')`


Gerar a pasta venv, caso ela n√£o exista:
- `python3 -m venv venv`


Ativar o venv:
- `source venv/bin/activate`


Instalar requerimentos:
- `pip install -r requirements.txt`


Rodar:
- `python main.py`


## API routes

### Vers√£o gratuita
POST -> http://0.0.0.0:8080/save_info
  Body:
  ```json
    {
      "url": "youtube.com"
    }
  ```

POST -> http://0.0.0.0:8080/save_rank
  Body: none

GET -> http://0.0.0.0:8080/get_info
  Body:
  ```json
    {
      "url": "youtube.com"
    }
  ```

GET -> http://0.0.0.0:8080/get_info_rank

### Vers√£o paga
POST -> http://0.0.0.0:8080/save_info_pro
  Body:
  ```json
    {
      "url": "youtube.com"
    }
  ```
GET -> http://0.0.0.0:8080/get_info_pro
  Body:
  ```json
    {
      "url": "youtube.com"
    }
  ```


# Introdu√ß√£o ao Teste

Este teste tem como objetivo uma API para scraping de dados do SimilarWeb e armazen√°-los em um banco de dados MongoDB. 

Utilizei a linguagem Python para desenvolver a solu√ß√£o.

O similarweb, contem diversas informa√ß√µes sobre acessos de website, principais paises, visitas por paginas e muito mais. 

Essa API captura todas essas informa√ß√µes üôÇ.

Porem √© paga. Para fazer o teste gratuito tem que colocar um cart√£o.

Optei por usar a [ferramenta gratuita](https://developers.similarweb.com/docs/digital-rank-api#get-started-with-website-digitalrank-api) para finalizar o teste.

Porem deixei pre configurado caso queiram testar com uma api key paga.

**Tasks:**

1. [x] **Desenvolvimento da API:**
    - [x] Implementar uma API que realize scraping de dados de websites listados e armazene as informa√ß√µes no MongoDB.
2. [x] **Endpoints da API:**
    - [x] **`POST /salve_info`**: Este endpoint deve receber uma URL de um site, realizar o scraping dos dados no SimilarWeb e salvar as informa√ß√µes no MongoDB.
    - [x] **`POST /get_info`**: Este endpoint deve receber uma URL, buscar as informa√ß√µes do site no banco de dados e retorn√°-las. 
    - [x] Se as informa√ß√µes ainda n√£o estiverem dispon√≠veis, deve retornar um c√≥digo de erro.
    

[x] **Requisitos T√©cnicos:**

## Vers√£o gratuita
- [x] As informa√ß√µes a serem salvas incluem: 
  - [x] Classifica√ß√£o;
  - [x] Site;
  - [x] Ranking dos sites mais visitados.

## Vers√£o paga
**N√£o est√° testado essa parte, porem de acordo com a [documenta√ß√£o](https://developers.similarweb.com/reference/api-lite), acredito que deva funcionar com uma api key paga:**
- [x] As informa√ß√µes a serem salvas incluem: 
  - [x] Classifica√ß√£o;
  - [x] Site;
  - [x] Categoria;
  - [x] Mudan√ßa de Ranking;
  - [x] Dura√ß√£o M√©dia da Visita;
  - [x] P√°ginas por Visita;
  - [x] Taxa de Rejei√ß√£o;
  - [x] Principais Pa√≠ses;
  - [x] Distribui√ß√£o por G√™nero;
  - [x] Distribui√ß√£o por Idade;
  - [x] entre outros dados dispon√≠veis.

- [x] [Ponto Extra] A API deve ser ass√≠ncrona, retornando um c√≥digo 201 com um ID para verifica√ß√£o posterior do status da opera√ß√£o.
- [x] [Ponto Extra] N√£o utilizar Selenium, Playwright, Cypress ou qualquer outro automatizador de navegador para o scraping.

**Crit√©rios:**

- [x] **Funcionalidade:** Capacidade de salvar informa√ß√µes conforme especificado.
- [x] **Efici√™ncia:** Implementa√ß√£o de uma API ass√≠ncrona com retorno de status adequado.
- [x] **Qualidade do C√≥digo:** O c√≥digo deve ser escrito em Python, priorizando clareza e manutenibilidade.
- [x] **Conformidade com Requisitos:** Ades√£o aos requisitos t√©cnicos, incluindo a proibi√ß√£o do uso de automatizadores de navegador.
